% !Mode:: "TeX:UTF-8"
\documentclass[10pt,journal]{IEEEtran}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{comment}
\usepackage{multirow}
\usepackage{diagbox}
\usepackage{ctex}

\graphicspath{figures/}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}

\hyphenation{on-chip real-time}

\begin{document}
\title{端口间缓存共享技术研究}
%\onecolumn
%\author{\IEEEauthorblockN{Baoliang Li}}

\author{Baoliang~Li, %~\IEEEmembership{Student Member,~IEEE,}
        Zeljko Zilic, %~\IEEEmembership{Senior Member,~IEEE,}
        Wenhua~Dou, %~\IEEEmembership{Non-Member,~IEEE}% <-this % stops a space
\thanks{Baoliang~Li and Wenhua Dou are with the College of Computer Science, National University of Defense Technology, Changsha 410073, P.R. China}%
\thanks{Zeljko Zilic are with Department of Electrical \& Computer Engineering, McGill University, Montreal H3A-2A7, Quebec, Canada}%
\thanks{Manuscript received XX XX, 2014; revised XX XX, 2014.}}

\markboth{Journal of XXX,~Vol.~XX, No.~XX, XX~2014}%
{Li \MakeLowercase{\textit{et al.}}: 端口间缓存共享技术研究}

\maketitle

\begin{abstract}
本文提出了种基于端口间缓存共享的方法。
\end{abstract}
\begin{IEEEkeywords}
Networks-on-Chip (NoC), buffer sharing
\end{IEEEkeywords}

\section{Introduction}
引言的写作思路：
（1）通常的路由器结构是每个输入端口有自己的缓存；这些缓存资源被组织成不同的虚通道。
（2）这种路由器的结构存在很大的问题，最关键是缓存的利用率不均衡而且很低。同一个端口内不同VC的利用率不同；不同端口间的缓存资源利用率也不同。
（3）针对前一种现象，ViChaR被提出；之后Lai提出另一种基于链表的等效而且低成本的实现方式；
（4）针对后一种情况，xx提出了partial sharing的方法，该方法假设某些路由端口之前有一部分FIFO是可以被两个端口共享的；但是，在任意时间该共享FIFO里只能存储一个端口的报文切片，当该报文的后续切片被阻塞时，该共享FIFO的利用率非常低；MH提出了一种细粒度的端口间的缓存共享（两篇论文）的方法；
（5）以上的两种方法由于支持的VC数可以很多，导致VC和SA仲裁非常复杂；另外这种方法都具有一个共同的问题：需要大量的控制存储资源来支持动态的VC分配和使用。
（6）另外，以上提出的两种提高缓存利用率的方法都是基于输入缓存的路由器结构；在这种结构中通常采用VC和SA仲裁来消除冲突，由于Allocator的匹配效率很低，导致路由器的吞吐率不高；相反，输出缓存的路由器具有很高的吞吐率，但是需要Crossbar和Memory有一定的加速比，难以在片上实现。在xx中提出一种DBS结构，这种结构采用分布式的存储器来模拟输出排队，在xx情况下可以达到97\%的吞吐率。但是，这种结构是另一种缓存共享的结构，可以极大的改善输入排队路由器的吞吐率。尽管分布的缓存资源可以被所有的端口使用，实现了端口间的缓存共享。但是，这种结构的缓存利用率依然不高，我们举例说明如下。

Proper buffer sizing and organization are essential to achieving optimal network performance

画2张图表示静态缓存分配存在的问题：（1）3x3 mesh的例子说明端口之间的利用率不平衡；(2)同一个端口内VC之间的利用率不平衡。以3x3的mesh网络为例，在热点流量情况下（中间节点为热点）来说，热点的N和S端口接受的流量是W和E的3倍。因而如果能让W和E端口使用更多的buffer，那么那么对于因减少流量控制造成的stall而引起的大的延迟是非常有好处的。最理想的办法是，令每个端口使用$B_p=B_{total}\times\frac{C_p}{\sum_{p=1}^NC_p}$的buffer.然后对于每个端口所能使用的$B_p$个slot进行动态的管理。此外，端口间的buffer共享还有利于改进公平性以及不同数据流的吞吐率。最后指出，只有将端口间和VC 间的缓存共享同时实现才能够提高和改进buffer的利用率，以实现用最少的buffer来实现最高的性能。因为input buffers account for a large fraction of the overall area and power budget of typical Network-on-Chip。

再画一张图表示当前动态VC分配所面临的信约耗尽问题。并指出Lai等人提出的拥塞避免算法可以避免端口间的拥塞，但是端口内同一个VC的拥塞却无法解决。Standford大学的方法可以解决这一问题。

当把这种共享缓存形式的路由器应用于CPU-GPU混合的系统中时，带来的问题会更大，主要原因在于：GPU流量很大会很快将VC耗尽，而CPU流量很小由于信约太少而导致过大的延迟。而CPU程序通常是延迟敏感的。

另外，完全动态的VC分配还会增加VCA和SWA的压力，而这两个流水段通常又处于路由器的关键路径上。

再画1张图表示当前动态方案可能面临的死锁问题以及相应的解决办法。

对相关研究现状的描述：Lai和VichaR的方法只解决了端口内的VC动态分配问题,此外DAMQ的方法访存周期较长（3拍），VCR的方法也只适用于同一个端口内，而且所解决的是在故障情况下的性能平滑下降问题。对于端口间的动态缓存管理，有一类方法方法采用完全共享的centralized buffer，这类方法属于精粒度的共享；还有一类方法采用不完全共享（DAC11），但是该方法不支持VC。而MH的方法只有在某个端口发生故障的情况下其对应的buffer才能够被其它端口使用，而且这种方法是全动态的，因而硬件开销很大。采用链表的方式实现的完全VC共享会消耗大量的存储资源和芯片面积，standford大学的研究结果表明这类方式虽然提高了资源的利用率但是开销是十分具大的，以16个VC为例，大概会引起60\%的开销。另外一方面，完全静态的方式又会严重影响性能。

对我们的方案的简单介绍：因而我们的方法是在二者之间进行折衷，采用部分动态的VC 共享方式，每个端口分配一定数量的容量较小的静态VC（大小为可实现100\%吞吐率的最小值），端口之间共享一定数量的动态VC。每个端口只有当新到达的报文与被阻塞的报文不属于同一条流而且占用动态VC的数量小于其配额时才会启用动态VC。

我们方案对上述几个问题的解决方法：（1）当某个端口的流量较少时，静态分配的VC足够支持切片数据的无阻塞移动。而当某些端口的流量较多时，共享的buffer则可以用来缓存大量的切片。由于静态分配的VC相当于是为每个端口预留的配额，因而可以有效的避免共享缓存被某个端口耗尽时对低速端口的影响。（2）同时，为了减轻VCA段的压力，我们可以还采用VVC映射的方法来动态的调整对动态缓存的使用。因为VCA通常处于关键路径上，这样的做法可以不影响路由器的关键路径。另外，我们所有的新增的硬件都可以并行的独立的操作，而而不对路由器的关键路径产生不利的影响。（3）由于对静态VC的访问消耗的能量要比动态VC要少，因而我们的设计的功耗效率也要比MH的方法要好。（4）对于死锁，我们的方案由于 存在静态配置的VC，因而采用合理的分配方案则可以实现死锁避免，而在MH的方案中，死锁是通过逃逸通道来避免的。

当前几乎所有的路由器都是输入排队的，因为输出排队需要每个端口以P倍的加速比运行才能达到100\%的吞吐率，而输入排队的路由器通常只有不到80\%的吞吐率。另外，输出排队由于需要复杂的仲裁等机制，功耗通常是输入排队系统的1.5倍以上。

利用链表的好处是可以充分利用存储资源，但是缺点是硬件开销太大。因此对于这些共享的存储体我们有以下几种组织方式。对每个memory bank设置一1个存储控制模块这样使用的总的控制寄存器的数量要比为每个端口所有的存储体设置一个共用控制器要节省很多的硬件资源。因此，我们的方法从两方面节省了开销，一方面是几个小的控制器；另一方面是我们提出的混合式的存储管理方法的动态存储容量要比同等大小的完全动态的管理方式要小很多。因，最后可以画一张表并给出一张图列不这些比较的结果。

我们的SWA要进行修改，由于属于同一个输入端口的不同的存储体可以支持并行的读写，因此SA段可以进行修改以支持这个特性。在通常的路由器中，每个输入端口有1个$V_s:1$的仲裁器用于选出该输入端口胜出的VC（在这一阶段解决了FIFO读冲突），每个输出端口有1个$P:1$的仲裁器用于选择最终胜出的端口（在这一阶段解决了FIFO的写冲突）；在MH的方案中，每个输入端口有1个$V_{max}:1$ 的仲裁器，每个输出端口有1个$P:1$ 的仲裁器；而在我们的方案中第一阶段有1个$V_s:1$和N个$V_d:1$的小的仲裁器组成（$V_s+N*V_d=V_{max}$）；而第二阶段每个输出端口有1个$(5+N):1$ 的仲裁器。通常逻辑综合可以发现我们的方案由于每个仲裁器都比较小，因而可支持的最高时钟频率也最大，另外硬件开销也可以进行一些比较。

还有就是硬件开销，由于MH的方案每个端口有一个较大的缓存器和一套控制逻辑，假设每个端口有B的缓存资源；那么free buffer tracker的开销为$B\times log_2 B$，header pointer 的开销是$V_{max}\times log_2 B$，tail pointer的开销是$V_{max}\times log_2 B$，下一跳指针的开销$B\times log_2 B$；5个端口总的控制开销为$10\times(B+V_{max})\times log_2B$；而在我们的方案中，由于总的缓存资源中有一部分会被独立分配给每个端口做为静态VC，而且剩下的动态缓存资源又被分为几个小的memory bank,每个memory bank需要的控制资源比较少，我们假设有一半的缓存分配给静态VC，那么我们的方法控制开销为$5\times(B+2V_{max})\times log_2(B/2)$；

另外，我们采用的VC重命名技术也在一定程度上简化了VCA的实现。关于VCA的实现，传统的方法在输入端采用V:1仲裁器，在输出端采用PV:1仲裁器；MH的方法输入端采用P个$V_{max}:1$ 仲裁器，输出端采用1个P:1仲裁器；而我们的方法，在输入端采用n个$V_i:1$仲裁器，其中（$\sum_{i}^nV_i=V_{max}$）,在输出端采用nP:1 仲裁器。采用几个小的仲裁器并行工作来代替一个较大的仲裁器的好处是降低硬件复杂度并易于提高主频。（考虑到同一个端口之间不需要进行匹配，能否利用n(P-1):1来代替）由于我们的方法在输入端有更多的请求胜出，因而更加有利于提高匹配的成功率。由于我们的方法在VCA以及SWA上都有较高的匹配成功率，可以预见我们的路由器可以提供较高的吞吐率。每个下游节点的memory bank配置发生变化时都会通知VCA，VCA据此来屏蔽不能用的VC段。这样就不会存在冲突了。

由于每个memory bank有独立的操控逻辑，因而我们支持的最大VC数可以比MH的方法要大。

VCA也需要修改。假设每个端口有m个静态VC，那么VCA的实现规则是对于所有请求，优先分配这m个静态vc，对于暂时没有被分配给静态VC 的请求，则为其分配一个各不相同的标识符VCID，通过该VCID在下一级路由器中再进行动态的VC分配。我们称这一个步骤为VC重命名技术，下一级可分配的动态VC数量与其可使用的动态bank 数有关。通过使用VC重命名技术，我们的设计极大的简化了VC分配器的复杂度，这也为提高系统的主频带来很大的好处。因为VCA通常在关键路径上。这样一来，我们的VCA的实现电路得到了极大的简化，画一张图给出对应的电路设计方法。为了支持这一改变，信约控制模块也要进行相应的改变，有m+1个信约计数器。注意：VC的重命名技术可能已经在MH和Lai的论文就已经实现。

我们的VA和SA都是基于优先级的，VA阶段优先分配静态VC，SA阶段优先仲裁静态VC。

有可能在为报文指定Memory bank时采用一定的策略，以提高其吞吐率。

这些共享的存储体每一个都独立的检测不同输入端口的流量状态（这些流量状态由若干个统计计数器来实现），并通过协商来确定每个存储体的分配方式以及分配的实际地址段。再加上我们的SWA段支持同一个端口的多个bank并行输出，因而有希望得到更高的吞吐率。在设计的过程中需要注意free-buffer-tracker的实现方法，这涉及到某个bank能否很快被别的端口使用。但是同时也会对系统的吞吐率有一些影响。

之前MH的方案还有下面的问题：由于每个端口的报文或者都存在一个memory bank里，或者与其它端口的报文存储在一起。这样的方法有以下问题：（1）去往不同端口的报文无法并行传输；我们的方案采用多个并行的存储体以减少这一影响。画图展示这一影响。实际上就是一种特殊的HoL。假设端口W到达的切片目的地为E和L，端口N和S都只产生目的端口为E的报文；在RR调度方式下，平均每3个周期服务1个W的E报文；而实际上，W端口中向L端口的切片在高度向E端口的切片时是无法前进的，由于读冲突的存在。

A High-Throughput Distributed Shared-Buffer NoC Router应该值得参考。其提高吞吐率的方法与我们的方法很像。类似的文章还有Achieving High-Performance On-Chip Networks with Shared Buffer Routers。但是，这两篇论文中给出的方法都不支持VC，是典型的虫孔路由器。

VC保证在同一个通道中的报文切片不会交错。

有关队列空满的信号由free buffer tracker模块产生。

\subsection{流量控制模块}
\subsubsection{最初的方法}
我们的流量控制模块有两根线，每根线负责其中模块中一个buffer段的信约，信约控制器自动进行信约维护。

我们的方法最重的一个特点是不增加VA和SA段的复杂性，因为这两段都处在路由器的关键路径上。

TAMS的硕士论文中指出，ViChaR的方式提高了一个端口内部的buffer利用率，但是也提高了设计的复杂性和功耗。

DAMQ的思路与ViChaR的区别在于DAMQ采用固定数量的VC，因而会出现HoL。

我们提出的是一种运行的VC自适应技术，之前基于RTC的研究属于面向应用的buffer sizing方法，属于设计时的方法。

ViChaR和RAVC的方法都需要对整个路由器进行重新设计，因而成本高。而我们的新方法则主要是在原来的基础上增加了些硬件来提高buffer的利用率。在做实验的时候我们可以统计每个buffer的利用率。

最终我们要与conventional router进行比较。而且重新设计和实现sink端以统计各种信息。

inter-port buffer sharing是我们论文的主题。

MH提出的RAVC方法虽然支持动态VC数量以避免HoL，但是控制罗男过于复杂，硬件成本过高，需要大量的额外的存储器和寄存器文件来存储控制信息。而我们的方法增加的硬件几乎都是简单的组合逻辑电路，因则硬件成本更低。由于我们采用可扩展的VC结构，因则降低了拥塞端口发生拥塞的可能，在一定程度上对避免HoL也有帮助。

buffer借用在热点流量情况下可能很有用，效果会很明显。而热点流量恰是Cache一致性能及MC访问的重要应用场景。

为了简化硬件设计，我们只允许每个VC被偷一次。

当需要进行VC间缓存共享时，通常的情况是这个端口已经很堵，因则借助端口内的缓存共享来改进性能的性能提升已经非常有限，而端口间缓存共享则没有这个问题。因为应用通常会呈现出流量在同一个路由器的不同端口间的不均衡分布情况，因而采用端口间共享对改进吞吐率有好处。当然，通道间共享和MH的工作都可以有效的防止HoL。因而二者熟优熟劣需要再进行考虑。当然，对于HoL问题，我们的方案可以在选择待偷端口时适当的考虑可能发生的阻塞。对于非均匀流量，特别是热点流量情况下，端口间的流量分布是严格不均匀的。

在进行仲裁时，应当给借用的buffer空间切片以较高的优先级，以方便其清空队列。借用冲突可以通过与victim端口的协商来实现，theif端口和victim端口之间可以通过req/ack来交互。

buffer的读写冲突可以通过独立的两对读写指针来实现，高位读写指针地址以1开头，低位读写指针地址以0开头。

本文的一个重要的目标是改进现在的NoC的buffer利用率，增强性能的同时避免不可接受的硬件开销以及影响关键路径。

我们的设计中，每个VC由两个FIFO组成，prime\_readd\_ptr和prime\_write\_ptr在非共享状态下用最高位做片选，在共享状态下由share信号选择高位地址，其自己的最高位置零。

我们的设计的目的在于同时不引入较大的硬件开销

提出一种新的流量控制方法，两根线，每根线负责维护信约模块中一个FIFO段的可用buffer空间。

之前的buffer共享策略没有考虑到恶意流占用很多buffer的情况，因而会对系统的加速比产生很大的影响。在具体做实验的时候我们可以通过综合流量发送1000个报文所用的时间来进行分析和说明。而我们的方法由于限制每个VC所用的buffer空间最大是3/2，因而会在一定程度上减轻这一影响。

模块划分：

1.流量控制模块：信约生成、信约跟踪。

2.借用buffer的管理模块：处理借用和非借用状态下的地址译码以及读写，仲裁，队列空满检测模块。

3.借且buffer读写控制模块。

4.借用buffer跟踪模块。

5.buffer借用状态机：buffer选择，协商，确认和释放。

\subsubsection{新想法}
共享的buffer分成几个bank，用以支持动态的VC分配和端口间的缓存调整。用一个状态机或者什么东西来定期的将空闲的bank分配给指定的比较忙碌的端口使用。

如果到达的报文不属于静态VC队头报文的数据流，那么就为他分配一个新的VC，并将该切片写入新的VC，多静态VC处移到动态VC后应当立即向源端返回一个信约，除非动态VC的缓存空间已经已经用完。之后每到达一个报文先看其是否属于某个数据流，如果都不属于，那么就为其分配新的VC，否则就写入相应的VC中去。这样做的目的是防止报文序。

\section{实验与评估}
缓存资源的使用比较：（1）列表比较资源；（2）实验比较性能，包括吞吐率和延迟；（3）综合结果比较面积和功耗。

\section{代码阅读重要提醒}
Router\_Checker在做综合的过程中要去掉。

VCR是带虚通道的路由器，RTR是SA与VA结合的实现方法，WHR是没有虚通道的实现方式。

代码中的buffer\_size是一个端口的buffer总量，每个VC的buffer数量还需要除以VC数量。

rtr\_flit\_buffer.v输入端口的管理模块

原子分配的时候这种优化策略可能没有效果。一般的VC路由器吞吐率比较高，原子VC分配只有当切片的信约返回时该VC才可用，而一般的VC则在尾切片离开VC时即可以再次进行分配。原子VC分配当VC很多时可以达到很高的性能。

在进行路由器综合时，mesh型拓扑结构中某些边缘路由器的某些端口可以不生成。

代码中的message\_class和resource\_class都是指什么意思？

拓扑结构的连接性包括线、环和全互连。

路由器的端口数量等于每个维度的邻居数乘以网络维度再加上每个路由器的节点数。

代码中的flow\_control\_bypass是什么意思？

link\_ctrl是指功耗控制相关的。flit\_ctrl呢？

看一下flit\_buffer的寄存器文件的实现方案。

随机拓扑的生成可以采用TGFF工具。

注意在VC和SW仲裁时VC非空和满时的选项

VC分配是否偏向空队列的选项

almost full的含义是只剩下1个buffer空间

\section*{Acknowledgement}
The authors thank the reviewers for their suggestions and comments, and all the experiments are carried out at the Integrated Microsystem Lab (IML) of McGill University. This research is supported by High Technology Research and Development Program of China (Grant No. 2012AA012201, 2012AA011902).

\bibliographystyle{unsrt}
\bibliography{Docear}

\end{document}
