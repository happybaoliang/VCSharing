% !Mode:: "TeX:UTF-8"
\documentclass[10pt,journal]{IEEEtran}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{comment}
\usepackage{multirow}
\usepackage{diagbox}
\usepackage{ctex}

\graphicspath{figures/}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}

\hyphenation{on-chip real-time}

\begin{document}
\title{端口间缓存共享技术研究}
%\onecolumn
%\author{\IEEEauthorblockN{Baoliang Li}}

\author{Baoliang~Li, %~\IEEEmembership{Student Member,~IEEE,}
        Zeljko Zilic, %~\IEEEmembership{Senior Member,~IEEE,}
        Wenhua~Dou, %~\IEEEmembership{Non-Member,~IEEE}% <-this % stops a space
\thanks{Baoliang~Li and Wenhua Dou are with the College of Computer Science, National University of Defense Technology, Changsha 410073, P.R. China}%
\thanks{Zeljko Zilic are with Department of Electrical \& Computer Engineering, McGill University, Montreal H3A-2A7, Quebec, Canada}%
\thanks{Manuscript received XX XX, 2014; revised XX XX, 2014.}}

\markboth{Journal of XXX,~Vol.~XX, No.~XX, XX~2014}%
{Li \MakeLowercase{\textit{et al.}}: 端口间缓存共享技术研究}

\maketitle

\begin{abstract}
本文提出了种基于端口间缓存共享的方法。
\end{abstract}
\begin{IEEEkeywords}
Networks-on-Chip (NoC), buffer sharing
\end{IEEEkeywords}

\section{Introduction}
引言的写作思路：
（1）通常的路由器结构是每个输入端口有自己的缓存；这些缓存资源被组织成不同的虚通道。
（2）这种路由器的结构存在很大的问题，最关键是缓存的利用率不均衡而且很低。同一个端口内不同VC的利用率不同；不同端口间的缓存资源利用率也不同。
（3）针对前一种现象，ViChaR被提出；之后Lai提出另一种基于链表的等效而且低成本的实现方式；
（4）针对后一种情况，xx提出了partial sharing的方法，该方法假设某些路由端口之前有一部分FIFO是可以被两个端口共享的；但是，在任意时间该共享FIFO里只能存储一个端口的报文切片，当该报文的后续切片被阻塞时，该共享FIFO的利用率非常低；MH提出了一种细粒度的端口间的缓存共享（两篇论文）的方法；
（5）以上的两种方法由于支持的VC数可以很多，导致VC和SA仲裁非常复杂；另外这种方法都具有一个共同的问题：需要大量的控制存储资源来支持动态的VC分配和使用。
（6）另外，以上提出的两种提高缓存利用率的方法都是基于输入缓存的路由器结构；在这种结构中通常采用VC和SA仲裁来消除冲突，由于Allocator的匹配效率很低，导致路由器的吞吐率不高；相反，输出缓存的路由器具有很高的吞吐率，但是需要Crossbar和Memory有一定的加速比，难以在片上实现。在xx中提出一种DBS结构，这种结构采用分布式的存储器来模拟输出排队，在xx情况下可以达到97\%的吞吐率。但是，这种结构是另一种缓存共享的结构，可以极大的改善输入排队路由器的吞吐率。尽管分布的缓存资源可以被所有的端口使用，实现了端口间的缓存共享。但是，这种结构的缓存利用率依然不高，我们举例说明如下。

Proper buffer sizing and organization are essential to achieving optimal network performance

画2张图表示静态缓存分配存在的问题：（1）3x3 mesh的例子说明端口之间的利用率不平衡；(2)同一个端口内VC之间的利用率不平衡。以3x3的mesh网络为例，在热点流量情况下（中间节点为热点）来说，热点的N和S端口接受的流量是W和E的3倍。因而如果能让W和E端口使用更多的buffer，那么那么对于因减少流量控制造成的stall而引起的大的延迟是非常有好处的。最理想的办法是，令每个端口使用$B_p=B_{total}\times\frac{C_p}{\sum_{p=1}^NC_p}$的buffer.然后对于每个端口所能使用的$B_p$个slot进行动态的管理。此外，端口间的buffer共享还有利于改进公平性以及不同数据流的吞吐率。最后指出，只有将端口间和VC 间的缓存共享同时实现才能够提高和改进buffer的利用率，以实现用最少的buffer来实现最高的性能。因为input buffers account for a large fraction of the overall area and power budget of typical Network-on-Chip。

再画一张图表示当前动态VC分配所面临的信约耗尽问题。并指出Lai等人提出的拥塞避免算法可以避免端口间的拥塞，但是端口内同一个VC的拥塞却无法解决。Standford大学的方法可以解决这一问题。

当把这种共享缓存形式的路由器应用于CPU-GPU混合的系统中时，带来的问题会更大，主要原因在于：GPU流量很大会很快将VC耗尽，而CPU流量很小由于信约太少而导致过大的延迟。而CPU程序通常是延迟敏感的。

另外，完全动态的VC分配还会增加VCA和SWA的压力，而这两个流水段通常又处于路由器的关键路径上。

再画1张图表示当前动态方案可能面临的死锁问题以及相应的解决办法。

对相关研究现状的描述：Lai和VichaR的方法只解决了端口内的VC动态分配问题,此外DAMQ的方法访存周期较长（3拍），VCR的方法也只适用于同一个端口内，而且所解决的是在故障情况下的性能平滑下降问题。对于端口间的动态缓存管理，有一类方法方法采用完全共享的centralized buffer，这类方法属于精粒度的共享；还有一类方法采用不完全共享（DAC11），但是该方法不支持VC。而MH的方法只有在某个端口发生故障的情况下其对应的buffer才能够被其它端口使用，而且这种方法是全动态的，因而硬件开销很大。采用链表的方式实现的完全VC共享会消耗大量的存储资源和芯片面积，standford大学的研究结果表明这类方式虽然提高了资源的利用率但是开销是十分具大的，以16个VC为例，大概会引起60\%的开销。另外一方面，完全静态的方式又会严重影响性能。

对我们的方案的简单介绍：因而我们的方法是在二者之间进行折衷，采用部分动态的VC 共享方式，每个端口分配一定数量的容量较小的静态VC（大小为可实现100\%吞吐率的最小值），端口之间共享一定数量的动态VC。每个端口只有当新到达的报文与被阻塞的报文不属于同一条流而且占用动态VC的数量小于其配额时才会启用动态VC。

我们方案对上述几个问题的解决方法：（1）当某个端口的流量较少时，静态分配的VC足够支持切片数据的无阻塞移动。而当某些端口的流量较多时，共享的buffer则可以用来缓存大量的切片。由于静态分配的VC相当于是为每个端口预留的配额，因而可以有效的避免共享缓存被某个端口耗尽时对低速端口的影响。（2）同时，为了减轻VCA段的压力，我们可以还采用VVC映射的方法来动态的调整对动态缓存的使用。因为VCA通常处于关键路径上，这样的做法可以不影响路由器的关键路径。另外，我们所有的新增的硬件都可以并行的独立的操作，而而不对路由器的关键路径产生不利的影响。（3）由于对静态VC的访问消耗的能量要比动态VC要少，因而我们的设计的功耗效率也要比MH的方法要好。（4）对于死锁，我们的方案由于 存在静态配置的VC，因而采用合理的分配方案则可以实现死锁避免，而在MH的方案中，死锁是通过逃逸通道来避免的。

当前几乎所有的路由器都是输入排队的，因为输出排队需要每个端口以P倍的加速比运行才能达到100\%的吞吐率，而输入排队的路由器通常只有不到80\%的吞吐率。另外，输出排队由于需要复杂的仲裁等机制，功耗通常是输入排队系统的1.5倍以上。

利用链表的好处是可以充分利用存储资源，但是缺点是硬件开销太大。因此对于这些共享的存储体我们有以下几种组织方式。对每个memory bank设置一1个存储控制模块这样使用的总的控制寄存器的数量要比为每个端口所有的存储体设置一个共用控制器要节省很多的硬件资源。因此，我们的方法从两方面节省了开销，一方面是几个小的控制器；另一方面是我们提出的混合式的存储管理方法的动态存储容量要比同等大小的完全动态的管理方式要小很多。因，最后可以画一张表并给出一张图列不这些比较的结果。

我们的SWA要进行修改，由于属于同一个输入端口的不同的存储体可以支持并行的读写，因此SA段可以进行修改以支持这个特性。在通常的路由器中，每个输入端口有1个$V_s:1$的仲裁器用于选出该输入端口胜出的VC（在这一阶段解决了FIFO读冲突），每个输出端口有1个$P:1$的仲裁器用于选择最终胜出的端口（在这一阶段解决了FIFO的写冲突）；在MH的方案中，每个输入端口有1个$V_{max}:1$ 的仲裁器，每个输出端口有1个$P:1$ 的仲裁器；而在我们的方案中第一阶段有1个$V_s:1$和N个$V_d:1$的小的仲裁器组成（$V_s+N*V_d=V_{max}$）；而第二阶段每个输出端口有1个$(5+N):1$ 的仲裁器。通常逻辑综合可以发现我们的方案由于每个仲裁器都比较小，因而可支持的最高时钟频率也最大，另外硬件开销也可以进行一些比较。

还有就是硬件开销，由于MH的方案每个端口有一个较大的缓存器和一套控制逻辑，假设每个端口有B的缓存资源；那么free buffer tracker的开销为$B\times log_2 B$，header pointer 的开销是$V_{max}\times log_2 B$，tail pointer的开销是$V_{max}\times log_2 B$，下一跳指针的开销$B\times log_2 B$；5个端口总的控制开销为$10\times(B+V_{max})\times log_2B$；而在我们的方案中，由于总的缓存资源中有一部分会被独立分配给每个端口做为静态VC，而且剩下的动态缓存资源又被分为几个小的memory bank,每个memory bank需要的控制资源比较少，我们假设有一半的缓存分配给静态VC，那么我们的方法控制开销为$5\times(B+2V_{max})\times log_2(B/2)$；

另外，我们采用的VC重命名技术也在一定程度上简化了VCA的实现。关于VCA的实现，传统的方法在输入端采用V:1仲裁器，在输出端采用PV:1仲裁器；MH的方法输入端采用P个$V_{max}:1$ 仲裁器，输出端采用1个P:1仲裁器；而我们的方法，在输入端采用n个$V_i:1$仲裁器，其中（$\sum_{i}^nV_i=V_{max}$）,在输出端采用nP:1 仲裁器。采用几个小的仲裁器并行工作来代替一个较大的仲裁器的好处是降低硬件复杂度并易于提高主频。（考虑到同一个端口之间不需要进行匹配，能否利用n(P-1):1来代替）由于我们的方法在输入端有更多的请求胜出，因而更加有利于提高匹配的成功率。由于我们的方法在VCA以及SWA上都有较高的匹配成功率，可以预见我们的路由器可以提供较高的吞吐率。每个下游节点的memory bank配置发生变化时都会通知VCA，VCA据此来屏蔽不能用的VC段。这样就不会存在冲突了。

由于每个memory bank有独立的操控逻辑，因而我们支持的最大VC数可以比MH的方法要大。

VCA也需要修改。假设每个端口有m个静态VC，那么VCA的实现规则是对于所有请求，优先分配这m个静态vc，对于暂时没有被分配给静态VC 的请求，则为其分配一个各不相同的标识符VCID，通过该VCID在下一级路由器中再进行动态的VC分配。我们称这一个步骤为VC重命名技术，下一级可分配的动态VC数量与其可使用的动态bank 数有关。通过使用VC重命名技术，我们的设计极大的简化了VC分配器的复杂度，这也为提高系统的主频带来很大的好处。因为VCA通常在关键路径上。这样一来，我们的VCA的实现电路得到了极大的简化，画一张图给出对应的电路设计方法。为了支持这一改变，信约控制模块也要进行相应的改变，有m+1个信约计数器。注意：VC的重命名技术可能已经在MH和Lai的论文就已经实现。

我们的VA和SA都是基于优先级的，VA阶段优先分配静态VC，SA阶段优先仲裁静态VC。

有可能在为报文指定Memory bank时采用一定的策略，以提高其吞吐率。

这些共享的存储体每一个都独立的检测不同输入端口的流量状态（这些流量状态由若干个统计计数器来实现），并通过协商来确定每个存储体的分配方式以及分配的实际地址段。再加上我们的SWA段支持同一个端口的多个bank并行输出，因而有希望得到更高的吞吐率。在设计的过程中需要注意free-buffer-tracker的实现方法，这涉及到某个bank能否很快被别的端口使用。但是同时也会对系统的吞吐率有一些影响。

之前MH的方案还有下面的问题：由于每个端口的报文或者都存在一个memory bank里，或者与其它端口的报文存储在一起。这样的方法有以下问题：（1）去往不同端口的报文无法并行传输；我们的方案采用多个并行的存储体以减少这一影响。画图展示这一影响。实际上就是一种特殊的HoL。假设端口W到达的切片目的地为E和L，端口N和S都只产生目的端口为E的报文；在RR调度方式下，平均每3个周期服务1个W的E报文；而实际上，W端口中向L端口的切片在高度向E端口的切片时是无法前进的，由于读冲突的存在。

片上网络中存在的几种形式的阻塞：因VC分配失败造成的阻塞对性能的影响最大，之间提出的动态VC分配实际上是在降低因为这一种形式的阻塞进而提高吞吐率降低延迟的。但是，这类动态VC分配方案的本质是为每个端口分配大量的VC，并实现同一个端口内的不同VC的动态缓存分配（为了防止死锁，每个VC需要至少保留一个缓存空间,剩余的缓存空间则可以在不同的VC之间进行动态的分配。) 实际上，造成VC阻塞的原因是大量不完整的报文（即尾切片还没有到达）占据了所有的VC。存在大量不完成报文的原因主要是因为阻塞造成的同一个报文的不同的切片跨跃存在于几个路由器中。换句话说，这些路由器中都会有一条VC被该报文所占据而无法被其它报文所利用。由于不同端口的流量情况不同。但是，某个端口的不完全报文的最大数量等于于上一级的所有路由器中需要向该路由器注入流量的VC的总数。VC保证在同一个通道中的报文切片顺序不会交错。

我们的方案为每个端口预留一定量的VC，然后剩余的VC被所有的端口共享。这样做的原因是为了为每个端口保证一定的吞吐率和带宽以避免当该端口出现猝发流量时没有可用VC的情况。预留不同数量的VC最终的性能是不同的，对于不同的流量模式可以进行多次实验找出最优的组合。目测发现这种部分虚通道共享方案对于热点流量效果会比较好，而热点流量又恰好对应于CMP系统中的MC或home节点。

之后MH提出的端口间缓存共享的方案实际上实现了端口间的缓存共享,以减少因流量控制而造成的吞吐率下降和延迟增加。但是因为流量控制而造成的阻塞造成的影响相对虚通道不足造成的影响较小。

我们提出的方案同时实现了端口间的缓存共享和虚通道共享，特别是端口间的虚通道共享对改进系统的吞吐率是非常有好处的，因为VC阻塞通常要较多的时钟周期。我们在做实验的时候还可以考虑这样一种情况：对于conventional router、damq路由器和我们提出的路由器结构而言，为了达到同样的性能，我们的方案在需要的缓存资源方面的节省情况。由于实现了端口间的VC共享，我们的方案还可以实现的另一个目标是减少每个VC仲裁器的开销。因为这个仲裁器通常处于路由器流水线中的关键路径上。为了采用较小的分配器来实现大量动态VC的分配，我们的方案要求每个输入端口要有一个VC分发逻辑。该逻辑还要实现VC的重定向以实现流量隔离，避免某个恶意数据流占据所有的缓存空间。

我们的方案具体如下：对于之前的共享VC方案，假设原来的动态VC方案中每个端口有x个VC，那么我们的方案每个端口设置5x/6个VC，另外还有5x/6个VC为各个端口间共享的。与之前的方案，对于同样的VC数量，每个VC仲裁器的复杂度则有所下降，而SW仲裁器的复杂度暂时无法分析得之。采用VC共享方案的本质原因是为了尽可以避免VC阻塞造成的性能下降。对于共享的VC我们称之为影子VC。原因是VC仲裁器没有专门的请求端口，而且与每个端口的对应vc共用一个请求端口，因为被分配的VC在尾切片没有到达之前是不会grant任何请求的，因而该端口可以被影子vc所使用。在我们的方案中，每个端口所能使用的vc数量在5x/6和10x/6之间，远远大于之前的设计方案，但是所用的vc分配器规模则远远小于之前的方案。实现这一目的的根本原因在于我们实现了vc arbiter的复用。为了区分这两类vc，我们需要在原来的channel总线中增加一根线表明当时到达的切片的vc id是对应于影子vc还是本原vc的。另外，我们还需要在channel总线中增加5x/6根线来表明每个影子vc是否可以被该端口用于vc分配。这些线由下流路由器中一个集中的控制逻辑驱动，该控制逻辑会根据每个端口对应的私有vc的占用情况来决定对应的影子vc是否分配给这个端口。5x/6个共享vc也是动态的分配缓存空间，为了避免写冲突，要求这些缓存空间被分成若干个小的存储体，这些存储体可以被并行的读写。每个存储体有自己的sw arbiter，因而我们的方案中sw allocator也需要重新设计。由于crossbar的端口数量也有所增加，因而也会很大程度上提高吞吐率。总起来说，我们的方案与conventional router相比实现的性能提升源于三个方面：（1）实现了动态的vc分配，提高了缓存的利用率，可以利用较少的缓存资源实现同样的性能；（2）实现了vc分配器的共享，进而降低了va的复杂度和实现成本；（3）实现了端口间的vc共享，通过发现不同端口间对vc数量的不同需求和共享，我们的方案实现了端口间vc共享进而降低了因vc不足造成的阻塞；（4）我们的方案通过发现不同端口间对缓存容量的不同需要，动态的分配缓存资源到不同的端口，因而实现了资源的高效利用并以此来提高片上网络的性能。与之前提出的动态vc分配的方案相比，我们的方案由于利用了分配器的复用技术，进而实现了利用较小的allocator来实现对大量vc的分配和使用，在很大程度上降低了allocator的实现成本并降低了关键路径长度，对于提高系统的主频非常有好处。另外，我们的vc分配应该只适用于原子vc分配？因为我们的方案中集中的控制器需要根据每个端口的vc的占用情况来动态的分配vc。在最终的实验比较中，我们可以考虑对于同样的性能，三种路由器的实现方案所需要的缓存资源各是多少。另外，我们还可以与mh的方案进行比较，如果没有猜错的话，mh的方案为了实现buffer共享，每个端口的next buffer slot ,header ptr和tail ptr应该都是可以寻址到该路由器中任何一个buffer slot的。因此，这种共享方案应该是非常耗资源的。

在我们的方案中，为了简化VC分配逻辑，我们在Vc分配和sw分配时给影子vc赋预较高的优先级，以让其尽快排空队列，这样方便其它端口使用。另外，共享的缓存区被分成5个或是5的整数倍数存储体，我们对vc的分配以存储体为粒度，如果某个存储体被分配给某个端口，那么对应于这个存储体的所有的vc也被赋予这个端口。当属于某个端口的共享存储中所有的vc都空闲时该存储体便可以被重新分配。之所以称之为影子vc是因为我们的方案中影子vc与端口的私有vc共享同一个sw端口和va端口，这样即实现了对大规模vc的支持双降低了设计成本。而实际上这样的设计并没有降低系统的性能。


考虑某种情况，当某条流在某个路由器中发生VC阻塞时，该条流会在路由器中积压大量的切片，而切片在缓存区中的积压会将该数据流转变成为恶意数据流。而造成这一现象的原因则是因为虚通道分配失败。因而我们的方案通过避免这种虚通道分配失败来提高吞吐率将对减轻恶意流的影响也会有好处。

A High-Throughput Distributed Shared-Buffer NoC Router应该值得参考。其提高吞吐率的方法与我们的方法很像。类似的文章还有Achieving High-Performance On-Chip Networks with Shared Buffer Routers。但是，这两篇论文中给出的方法都不支持VC，是典型的虫孔路由器。


有关队列空满的信号由free buffer tracker模块产生。

\subsection{流量控制模块}
\subsubsection{最初的方法}
我们的流量控制模块有两根线，每根线负责其中模块中一个buffer段的信约，信约控制器自动进行信约维护。

我们的方法最重的一个特点是不增加VA和SA段的复杂性，因为这两段都处在路由器的关键路径上。

TAMS的硕士论文中指出，ViChaR的方式提高了一个端口内部的buffer利用率，但是也提高了设计的复杂性和功耗。

DAMQ的思路与ViChaR的区别在于DAMQ采用固定数量的VC，因而会出现HoL。

我们提出的是一种运行的VC自适应技术，之前基于RTC的研究属于面向应用的buffer sizing方法，属于设计时的方法。

ViChaR和RAVC的方法都需要对整个路由器进行重新设计，因而成本高。而我们的新方法则主要是在原来的基础上增加了些硬件来提高buffer的利用率。在做实验的时候我们可以统计每个buffer的利用率。

最终我们要与conventional router进行比较。而且重新设计和实现sink端以统计各种信息。

inter-port buffer sharing是我们论文的主题。

在做实验时可以考虑不同的报文长度以模拟cache一致性协议的需求，例如将报文长度取双峰分布，一个长度为1(对应读请求或者写响应消息)一个长度为16（对应cache行）。

MH提出的RAVC方法虽然支持动态VC数量以避免HoL，但是控制罗男过于复杂，硬件成本过高，需要大量的额外的存储器和寄存器文件来存储控制信息。而我们的方法增加的硬件几乎都是简单的组合逻辑电路，因则硬件成本更低。由于我们采用可扩展的VC结构，因则降低了拥塞端口发生拥塞的可能，在一定程度上对避免HoL也有帮助。

buffer借用在热点流量情况下可能很有用，效果会很明显。而热点流量恰是Cache一致性能及MC访问的重要应用场景。

为了简化硬件设计，我们只允许每个VC被偷一次。

当需要进行VC间缓存共享时，通常的情况是这个端口已经很堵，因则借助端口内的缓存共享来改进性能的性能提升已经非常有限，而端口间缓存共享则没有这个问题。因为应用通常会呈现出流量在同一个路由器的不同端口间的不均衡分布情况，因而采用端口间共享对改进吞吐率有好处。当然，通道间共享和MH的工作都可以有效的防止HoL。因而二者熟优熟劣需要再进行考虑。当然，对于HoL问题，我们的方案可以在选择待偷端口时适当的考虑可能发生的阻塞。对于非均匀流量，特别是热点流量情况下，端口间的流量分布是严格不均匀的。

在进行仲裁时，应当给借用的buffer空间切片以较高的优先级，以方便其清空队列。借用冲突可以通过与victim端口的协商来实现，theif端口和victim端口之间可以通过req/ack来交互。

buffer的读写冲突可以通过独立的两对读写指针来实现，高位读写指针地址以1开头，低位读写指针地址以0开头。

本文的一个重要的目标是改进现在的NoC的buffer利用率，增强性能的同时避免不可接受的硬件开销以及影响关键路径。

我们的设计中，每个VC由两个FIFO组成，prime\_readd\_ptr和prime\_write\_ptr在非共享状态下用最高位做片选，在共享状态下由share信号选择高位地址，其自己的最高位置零。

我们的设计的目的在于同时不引入较大的硬件开销

提出一种新的流量控制方法，两根线，每根线负责维护信约模块中一个FIFO段的可用buffer空间。

之前的buffer共享策略没有考虑到恶意流占用很多buffer的情况，因而会对系统的加速比产生很大的影响。在具体做实验的时候我们可以通过综合流量发送1000个报文所用的时间来进行分析和说明。而我们的方法由于限制每个VC所用的buffer空间最大是3/2，因而会在一定程度上减轻这一影响。

模块划分：

1.流量控制模块：信约生成、信约跟踪。

2.借用buffer的管理模块：处理借用和非借用状态下的地址译码以及读写，仲裁，队列空满检测模块。

3.借且buffer读写控制模块。

4.借用buffer跟踪模块。

5.buffer借用状态机：buffer选择，协商，确认和释放。

我们的共享虚通道技术为每个端口预留少量的VC以减少VC仲裁和分配的压力，为了保证最差情况下的延迟性能，我们需要一种技术来确定每个虚通道所需要的最少的buffer slot数量。这就是我们之前基于RTC的论文所要解决的问题，由于在动态VC共享方案中每个VC只需要保留1个buffer slot便可以保证无死锁。我们的方案采用RTC的方法来确定每个VC所需要分配的最少缓存区。对于热点流量来说，特别是热点处于mesh网络的四个角上或者四条边上的时候，热点路由器和一些其它的路由器总有某些端口的缓存是没有被利用的。不光这些缓存区是没有被利用的，就连这些端口所对应的VC也是无法被有效使用的。因此我们可以考虑共享一部分缓存区和VC，之前MH的方案中VC是每个端口所独有的，没有被共享；为了保证性能，需要为每个端口预留大量的VC才能保证性能。但是这无疑增加了硬件成本降低了资源利用率。共享缓存技术除了增加资源利用率以外，还增加了实现了动态VC分配中间出现的流量隔离技术。

\subsubsection{新想法}
共享的buffer分成几个bank，用以支持动态的VC分配和端口间的缓存调整。用一个状态机或者什么东西来定期的将空闲的bank分配给指定的比较忙碌的端口使用。

如果到达的报文不属于静态VC队头报文的数据流，那么就为他分配一个新的VC，并将该切片写入新的VC，多静态VC处移到动态VC后应当立即向源端返回一个信约，除非动态VC的缓存空间已经已经用完。之后每到达一个报文先看其是否属于某个数据流，如果都不属于，那么就为其分配新的VC，否则就写入相应的VC中去。这样做的目的是防止报文序。

\section{实验与评估}
缓存资源的使用比较：（1）列表比较资源；（2）实验比较性能，包括吞吐率和延迟；（3）综合结果比较面积和功耗。

\section{代码阅读重要提醒}
Router\_Checker在做综合的过程中要去掉。

VCR是带虚通道的路由器，RTR是SA与VA结合的实现方法，WHR是没有虚通道的实现方式。

代码中的buffer\_size是一个端口的buffer总量，每个VC的buffer数量还需要除以VC数量。

rtr\_flit\_buffer.v输入端口的管理模块

原子分配的时候这种优化策略可能没有效果。一般的VC路由器吞吐率比较高，原子VC分配只有当切片的信约返回时该VC才可用，而一般的VC则在尾切片离开VC时即可以再次进行分配。原子VC分配当VC很多时可以达到很高的性能。

在进行路由器综合时，mesh型拓扑结构中某些边缘路由器的某些端口可以不生成。

代码中的message\_class和resource\_class都是指什么意思？

拓扑结构的连接性包括线、环和全互连。

路由器的端口数量等于每个维度的邻居数乘以网络维度再加上每个路由器的节点数。

代码中的flow\_control\_bypass是什么意思？

link\_ctrl是指功耗控制相关的。flit\_ctrl呢？

看一下flit\_buffer的寄存器文件的实现方案。

随机拓扑的生成可以采用TGFF工具。

注意在VC和SW仲裁时VC非空和满时的选项

VC分配是否偏向空队列的选项

almost full的含义是只剩下1个buffer空间

\section*{Acknowledgement}
The authors thank the reviewers for their suggestions and comments, and all the experiments are carried out at the Integrated Microsystem Lab (IML) of McGill University. This research is supported by High Technology Research and Development Program of China (Grant No. 2012AA012201, 2012AA011902).

\bibliographystyle{unsrt}
\bibliography{Docear}

\end{document}
